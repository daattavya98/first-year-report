\chapter{A theoretical framework}
\textit{Conjecture space and interestingness}\\
\textit{Multi-agent systems for mathematical discovery (Nature of mathematical discovery discussed in introduction in detail)}

\section{The Conjecture Space}
\label{sec:conj-space}
The conjecture space was introduced in \cite{mishraConjGen2023} by Mishra et.al. This framework can be utilized as a tool to study conjectures that can be expressed as inequalities involving continuous functions. This is a starting point to explore the notion 
of a space of conjectures as a meta-mathematical tool that can be used for mathematical dicovery across sub-disciplines. One of the major goals of my thesis is to try to extend the formalism beyond inequalities involving continuous functions and cover wider classes of mathematical statements. 
I describe the conjecture space along with some useful results that help setup the arguments in this report below (\textit{In preparation: Challenger Mishra, Rahul Sarkar and Daattavya Aggarwal}).

\begin{definition}[Relation Space]
    \label{def:space-relations}
    Let $\Omega\in\R^n$ be a compact subset. Let $C(\Omega)$ denote the Banach space of continuous, real-valued functions on $\Omega$, equipped with the supremum norm, i.e.
    \begin{equation*}
        \norm{f}_{C(\Omega)} := \sup_{x\in\Omega} \left|f(x)\right|    
    \end{equation*}
    where a real-valued function is
    \begin{equation*}
        f:\Omega\rightarrow\R
    \end{equation*}
    We will call this Banach space as the \textit{Relation Space}, $\crlR$
\end{definition}

Following on from the definition of the Relation space ~\ref{def:space-relations}, we can define the \textit{Conjecture Space} as follows:
\begin{definition}[Conjecture Space]
    \label{def:conj-space}
    Let $f\in\crlR$. $f$ is an element of the \textit{Conjecture Space} if and only if $f(x) < 0 \;\forall x\in\Omega$ or $f(x) > 0 \; \forall x\in\Omega$.
    The set $\crlC = \crlC_{<}\cup\crlC_{>}$ is called the \textit{Conjecture Space} where $\crlC_{<} = \{f\in\crlR\;|\; f(x)<0\;\forall x\in\Omega\}$ and $\crlC_{>} = \{f\in\crlR\;|\;f(x)>0\;\forall x\in\Omega\}$.
    $\crlC_{<}$ and $\crlC_{>}$ are disjoint convex sets.
\end{definition}

There are some useful properties of $\crlC$ building upon \cite{mishraConjGen2023}. (Please see appendix \ref{app:conj-space} for further details).
\begin{itemize}
    \item $\crlC$ is an open subset of $\crlR$ and hence a Banach manifold. $\crlC_{<}$ and $\crlC_{>}$ are homeomorphic. (Note that $\crlC$ is not a Banach space. For example, it is not closed under addition)
    \item $\crlC$ forms an abelian group under (pointwise) multiplication. Moreover, $\crlC$ and $\crlC_{>}$ are topological groups with the subspace topology inherited from $\crlR$. 
\end{itemize}

\begin{lemma}[Action by $\text{Homeo}(\R^*)$]
    \label{lemma:homeo-action}
    $\crlC$ admits a group action $\mathsf{A}: \text{Homeo}(\R^*)\times\crlC\mapsto\crlC$ by elements of the group $\text{Homeo}(\R^*)$ defined by $\mathsf{A}(g,f) := g\circ f$\\
    Every $g\in\text{Homeo}(\R^*)$ defines a homeomorphism $\mu_g : \crlC\mapsto\crlC$ by $\mu_g(f) = \mathsf{A}(g,f)$. The restriction of $\mu_g$ on each of the connected components $\crlC_{<}$ and $\crlC_{>}$ is also a homeomorphism 
    with exactly one of the two cases holding: (i) $\mu_g(\crlC_{>}) = \crlC_{>},\; \mu_g(\crlC_{<}) = \crlC_{<}$ or (ii) $\mu_g(\crlC_{>}) = \crlC_{<},\; \mu_g(\crlC_{<}) = \crlC_{>}$.
\end{lemma}

Based on ~\ref{lemma:homeo-action}, we can define a notion of \textit{equivalent} conjectures.
\begin{definition}[Equivalent Conjectures]
    Two conjectures $f_1,f_2\in\crlC$ are said to be \textit{equivalent} if there exists a homeomorphism $h\in\text{Homeo}(\R^*)$ such that $\mathsf{A}(h, f_1) = f_2$. We write this as $f_1\sim f_2$.
\end{definition}    

\begin{prop}
    Equivalence of conjectures forms an equivalence relation under the group action $\mathsf{A}$.
\end{prop}
\begin{proof}
    I check the three required properties explicitly.
    \begin{itemize}
        \item \textbf{Reflexivity:} $f\sim f$ as $\mathsf{A}(\mathsf{I}, f) = \mathsf{I}\circ f = f$ where $\mathsf{I}$ is the identity homeomorphism.
        \item \textbf{Symmetry:} 
            \begin{align*}
                f_1\sim f_2 &\implies \exists h\in\text{Homeo}(\R^*) \text{ such that } \mathsf{A}(h, f_1) = f_2\\
                &h\in\text{Homeo}(\R^*)\implies \exists h^{-1}\in\text{Homeo}(\R^*) \text{ such that } \mathsf{A}(h^{-1}, f_2) = f_1\\
                &\implies f_2\sim f_1
            \end{align*}
        \item \textbf{Transitivity:}
            \begin{align*}
                f_1\sim f_2 &\implies \exists h_1\in\text{Homeo}(\R^*) \text{ such that } \mathsf{A}(h_1, f_1) = f_2\\
                f_2\sim f_3 &\implies \exists h_2\in\text{Homeo}(\R^*) \text{ such that } \mathsf{A}(h_2, f_2) = f_3\\
                &\implies \mathsf{A}(h_2, \mathsf{A}(h_1, f_1)) = f_3\\
                &\implies \mathsf{A}(h_2\circ h_1, f_1) = f_3\\
                &\implies f_1\sim f_3    
            \end{align*}
    \end{itemize}
\end{proof}

Now crucially, we want to ensure that our notion of \textit{equivalence} doesn't make the conjecture space trivial, that is, there is more than one equivalence class under this relation. This is equivalent to the existence of more than one orbit under the group action $\mathsf{A}$.
The next result ensures this.

\begin{theorem}[Orbit Characterization]
    Let $f_1, f_2\in\crlC$. $f_1,f_2$ belong to different orbits of $\mathsf{A}$, if there exist distinct points $x,y\in\Omega$ such that either (i)$f_1(x) = f_1(y)$ and $f_2(x)\neq f_2(y)$ or (ii)$f_1(x)\neq f_1(y)$ and $f_2(x) = f_2(y)$. The converse holds when $\Omega$ is path-connected.
\end{theorem}


% \subsection{Relevant functional analysis stuff}
% cite (Challenger paper) Might be able to extend the conjecture/relation space to a Banach lattice and not just a Banach space.
\section{Connexions to model theory}
A major portion of my first year has been devoted to learn about model theory. I am trying to explore if there are connections to and tools from model theory that can be used to analyze the conjecture space in a systematic way and extend the formalism to a more general setting, i.e., beyond inequalities of continuous functions.
\subsection{Why model theory?}
In \cite{baldwin2020reasonable}, Baldwin contrasts Wigner's famous observations in \cite{wigner1990unreasonable} about the `unreasonable' effectiveness of mathematics in the natural sciences with the reasonable effectiveness of model theory across various areas of mathematics. Baldwin describes three key reasons for this effectiveness.
I believe these complement the conceptual framework of mathematical discovery that I am proposing for my thesis. These are as follows:
\begin{itemize}
    \item Representing an area of mathematics as the study of a collection of similar structures for a fixed vocabulary. Model theory has made rigorous the concept of \textit{interpretations}. This lets us compare these similar structures and know when they are equivalent, through notions like \textit{elementary equivalence}\footnote[1]{Please see \ref{def:elementary-equivalence}}.
    \item Restriction to \textit{definable}\footnote[2]{Please see \ref{def:definable-set}} subsets rather than all subsets of the structure.
    \item Results from \textit{Stability theory} which highlight combinatorial features that are present in very distinct areas of mathematics. 
\end{itemize} 

The crucial argument is captured by part of Baldwin's theses in \cite{Baldwin_2018} on contemporary model theory and the philosophy of mathematical practice.
\begin{itemize}
    \item The focus of contemporary model theory is utilizing formalization of \textit{specific} mathematical areas to investigate mathematical problems in general and issues in the philosophy of mathematics (methodology, axiomatization, compactness etc.)
    \item Modern model theory allows us to systematically compare \textit{local} formalizations for distinct mathematical areas allowing us to organize them and analyze mathematical practice.
\end{itemize}

I believe this focus on \textit{local} formalizations of specific areas is an essential feature of a math discovery system. This emulates the process of working mathematicians and avoids some of the shortcomings of global formalization. The decisive advantage of model theory is the ability to \textit{systematically compare} these formalizations and \textit{classify theories}\footnote[3]{A formal theory is a set of sentences in a formal language \cite{changModelTheory1990}}.
These are \textit{meta-mathematical tools} (Initially coined by the famous logician Tarski). They allow us to study these local theories as mathematical objects themselves. \\
Restriction to \textit{definable} subsets is natural and desirable in most of mathematics. Speaking loosely, `definable' objects in a structure are those which arise naturally, that is, when pathological cases are disallowed. As an example, focus on definable sets has led to understanding the method of quantifier elimination \cite{robinsonApplicationSymbolicLogic1952,TarskiDecisionMethod} which has wide ranging applications in algebra and field theory.
Stability theory has led to a  new direction that is epistemologically fruitful: the classification of complete, first-order theories into finitely many kinds. This allows for comparisons amongst local formalizations as described above.\\
A combination of these tools led to the discovery of \textit{o-minimality} in the 1980s \cite{pillayDefinableSetsOrdered1986, DENDRIES198497}. o-minimality has had successful applications in arithmetic geometry \cite{binyaminiWilkiesConjecturePfaffian2022,binyaminiBoundsRationalPoints2023}, analysis \cite{pilaOminimalityAndreOortConjecture2011}, hodge theory and recently even string theory \cite{douglasTamenessQuantumField2022,grimmComplexityTameQuantum2023,grimmFinitenessTheoremsCounting2023,grimmTamenessStringsDistance2022}!
Importantly, definability and o-minimality in particular are thought of as realizations of `tameness' and Grothendieck's `tame topology' \cite{acampoGrothendieckTameTopology2016, piekoszTameTopology2023}.
\par
Some of the central questions I am interested in potentially link contemporary model theory to mathematical discovery:
\begin{itemize}
    \item Are there well understood meta-mathematical (model theoretic) tools that can be incorporated to improve our math discovery system?
    \item Is an emphasis on `tameness' useful for a math discovery system?
\end{itemize}


% \input{Banach_space_model_theory_notes.tex}
\subsection{Connexions between o-minimality and \texorpdfstring{$\mathcal{C}$}{C}}
\label{sec:ominimal-connexions}
The analysis below is limited to the implementation of the conjecture space
on a computer (See \ref{sec:implementation} for further details).\\ 
This means I only consider a \textit{finite} number of continuous functions. Thus $\mathcal{R}$ and $\mathcal{C}$ will be \textit{finite}-dimensional Banach spaces rather than infinite-dimensional. This greatly simplifies the analysis. However, after conversations with Professor Jonathan Kirby (Reader in mathematical logic at University of East Anglia) and Professor Anuj Dawar (Department of Computer Science and Technology, University of Cambridge), it is very likely that to fully utilise tools from model theory, we have to extend our analysis to the more general, infinite-dimensional case.
This is a major area of interest that I plan to work on during the coming terms, potentially in collaboration with Professor Kirby and Professor Dawar. I present the current state of the analysis below.\\
% \input{o-minimal_details.tex}

Consider $\R_{alg}$\cite{Dries_1998}, the simplest o-minimal structure whose definable sets are exactly the semi-algebraic sets (See \ref{def:semialgebraic-set}). We are interested in analysing elements of the Relation space, $\crlR$.
These are $C^0$ real-valued functions, $f:\Omega\mapsto\R$, where $\Omega$ is a compact subset of $\R^n$.

By the Heine-Borel theorem \cite{Caradus_1967}, $\Omega$ must be closed and bounded. By definition, a bounded set is contained in an open ball, $B(a,r) = \{x\in\R^n:|x - a| < r\}$. \\$B(a, r)$ is definable in $\R_{alg}$, by the following first-order formula:

\begin{equation*}
    \exists r\;\forall x \quad (x - a) < r\; \vee \; (a - x) > r
\end{equation*}

This implies $\Omega$ is definable in our structure.

Now consider a  finite set of $C^0$ real-valued functions, $f:\Omega\mapsto\R$. This will be called the function box: $\mathcal{F} = \{f_1,...,f_k\}$. Associated to $\mathcal{F}$ is a tuple of coefficients, $\alpha = (\alpha_1,...,\alpha_k)$ where each $\alpha_i\in\R$.

The elements of $\mathcal{F}$ are the functions we want to appear in our conjectures. The optimization problem is finding the possible tuples $\alpha$ such that our loss is exactly zero. This is equivalent to the following condition:
\begin{equation}
    \label{loss}
    \alpha_1f_1(x)+\alpha_2f_2(x)+.....+\alpha_nf_n(x) > 0 \quad\forall x\in\Omega
\end{equation}

We now have the following possibilities:
\begin{itemize}
    \item All $f_i$'s are definable functions (See \ref{def:definable-function}): In this case, as a linear combination of definable functions will necessarily be definable, conjectures are definable.
    \item \textit{Approximation of functions}: Suppose one or more of the $f_i$'s are not definable. When calculating the loss as in \ref{loss}, on any computing system, we are necessarily restricted to a \textit{finite} number of computations.
          This is because $\Omega$ will always be finite. In this case, all of the $f_i$'s become discrete. By almost a trivial argument, we have the following:\\
        Suppose the implementation of $\Omega$ on the computing system is represented by $\Omega^{comp}$. This is the set
        \begin{equation*}
            \Omega^{comp} = \{(a_i) : i\in \mathbb{N}\} 
        \end{equation*}
        and each $a_i$ (term in the domain) is a real number up to arbitrary precision in floating point arithmetic.
        For any
        \begin{equation*}
            f:\Omega^{comp}\mapsto\R,
        \end{equation*}
        $f(\Omega^{comp})$ is a \textit{finite} subset of $\R^n$. A finite subset of $\R^n$ is trivially definable in $\R_{alg}$. Thus the domain and co-domain of $f$ are definable.
        \par Now, the graph of $f$ is a finite union of points,
        \begin{equation}
            \label{eq:graph}
            \Gamma(f) = \{(a_i, f(a_i)): a_i\in\Omega^{comp}\}
        \end{equation}
        As this is again a finite subset of $\R^n$, the discrete versions of $f_i$'s are definable.
\end{itemize}

From the above results, we can consider an alternate formulation for implementing the conjecture space. When dealing with discrete functions, we can replace them by their graphs as in \ref{eq:graph}. Now they are simply constants. We can now append $c_1,...,c_n$, to our first-order language where each $c_i$ represents a $f_i(\Omega^{comp})$. The conjecture space in this case simplifies to the definable set satisfying the following formula:

\begin{equation}
    \label{eq:def-conj-space}
    \exists\alpha_1\alpha_2....\alpha_n\quad\alpha_1c_1+\alpha_2c_2+...+\alpha_nc_n > 0
\end{equation}

Some of the questions to explore are: 
\begin{itemize}
    \item Are there model theoretic tools we can apply to the definable set in \ref{eq:def-conj-space}?
    \item Is there any connection between `meta-properties' of the conjectures (interesting/trivial conjectures for example) and o-minimal properties of this definable set (finiteness, stratifications, decompositions etc. \cite{Dries_1998}) Can these connections be leveraged in a meaningful way?
\end{itemize}

As mentioned in the introduction to this section, the above analysis can potentially become a lot more interesting once we can analyse the infinite dimensional case. I believe that the convergence results presented in \cite{thomasConvergenceResultsFunction2012} is a promising starting point to extend this analysis.
\begin{remark}
    Another possible source of model theory connections is to work with continuous logic rather than discrete logic and utilise results from model theory on Banach spaces \cite{yaacovModelTheoryMetric2008}. Continuous first-order logic (CFO) is a generalisation of first-order logic (FOL) (Simply consider any structure in FOL as a metric structure where the underlying metric $d$ is discrete, i.e, $d(a, b) = 1$ for distinct $a, b$). Basic results that hold in CFO can be framed as generalisations of corresponding results in FOL. 
    This direction might turn out to be more fruitful as Banach spaces are more natural objects in this setting. I am currently working through \cite{yaacovModelTheoryMetric2008} and attempting to incorporate these ideas in an application, \ref{sec:abc-conjecture}.   
\end{remark}

\section{Theorem spaces}
Whilst a ``space of conjectures'' is a potentially large leap from current literature, a related concept, ``space of theorems'', can be tackled via a variety of tools.
I define the ``space of theorems'', $\mathfrak{T}$ is the space of mathematical theorems. Note that this is a subset of the conjecture space as every element of $\mathfrak{T}$ trivially satisfies the membership criteria, i.e.,
there are no counter-examples to the theorem on any domain.
$\mathfrak{T}$ itself contains a furthermore rigorous subset, $\mathfrak{T}_F$, the ``space of formal theorems''. $\mathfrak{T}_F$ is the set of theorems that have been formalized in any formal system. Clearly $\mathfrak{T}_F\subset\mathfrak{T}$. A potential upside of working with $\mathfrak{T}_F$ is that their is a growing database of formalized theorems due to the widespread interest and ingenuity of the formalization community \cite{formalization_examples}.
Moreover a number of recent results have been published by training models by learning on datasets of formal theorems \cite{Deepmind_stuff}. A natural direction of inquiry is what is the relationship between these spaces? What is the connexion, if any, between the elements of these spaces?
\\\par
It is clear that $\mathfrak{T}_F\subset\mathfrak{T}\subset\mathfrak{Conj}$. The datasets based on $\mathfrak{T}_F$ can be leveraged for a variety of learning techniques. These models have achieved state-of-the-art accuracies on solving benchmark mathematics problems such as miniF2F, ProofNet, MATH and competition problem datasets such as IMO 2024 and the recently introduced PutnamBench. Improving AI models' ability to solve these tasks with formally verified proofs
is an extremely active and fruitful area of research. However, I argue that there is an obstruction to these models proving helpful for research and discovery in mathematics. I expand on this issue in an article I am currently working on (preprint to be available soon). 

\textcolor{red}{
An essential feature in applications of formalization and formal datasets is that an informal proof/solution already exists. Informal in this context refers to the notion of a formal proof as verified by a theorem proving system. Note that while the ability to formalize is at the heart of the field of mathematics and acceptance of proofs,
it is not a target that the working mathematician ever seeks to achieve in practice. The working mathematician's goal is to find proofs at the level of certainty that is accepted by the mathematical community and is fruitful to the progress of the discipline as a whole. Formal proofs as produced by systems such as Lean, Isabelle, Coq etc., although conceptually crucial, are often unintelligble to humans and well beyond the level of rigour that is needed by the community. Many formalization details are simply unnecessary and
intuitively already understood and internalized by mathematicians. Moreover, details of formalization can on occasion be extremely tedious and don't provide further insight into the problem.
\\
“My intellect never quite recovered from the strain of
writing [Principia Mathematica]. I have been ever since
definitely less capable of dealing with difficult
abstractions than I was before.” (Russell, Autobiography)
However, formalization is quickly becoming widely accepted by the mathematical community and is quickly becoming the expected standard for published research \cite{Tao, formalization_projects_to_check_shit}.
Increasing specialization making reviewing almost impossible, mistakes in math literature etc and the utility of previously models increasing.
}

The existence of solutions to problems in these datasets and ``informal'' proofs in literature are essential for these models to work as the existence of solutions and proofs \textbf{implies} that there is a configuration of axioms and deduction rules in your chosen formalization system that verifiably solves the problem/proves the theorem at hand.
The knowledge of the existence of such a solution/proof can by definition not exist for \textbf{new} research. Moreover, the set of possible formal statements is closed. This is because every element of $\mathfrak{T}_F$ is characterized by a specific \textit{deduction}\footnote[1]{A deduction from a set of sentences $\Gamma$ is a finite sequence \textbf{D} of formulas such that whenever a formula $A$ occurs in the sequence \textbf{D}, then either (i) $A\in\Gamma$, (ii) $A$ is an axiom (iii) A follows from the allowed inference rules applied to a sequence of formulas already appearing in \textbf{D}} in your chosen system of axioms and inference rules. 
If one works in classical logic, every well-formed formula in a given interpretation can only be either true or false. This implies that the concept of ``conjectures'' cannot exist in such a framework. By definition any well-formed formula is either true or false
and any statement that is not a well-formed formula simply cannot be parsed. Historically, mathematics has never developed in a ground up manner where every statement made is a logical consequence of previous statements. The ability to conjecture and pose questions (without knowing the answer) is crucial to mathematical research and creativity. As such, I would argue that it is unlikely to discover new, non-trivial mathematical results while being restricted to only making completely rigorous formal \textit{deductions}. Such a feat would be unprecedented.
However, including a ``pedantic'' formalizer as an agent in the process of discovery could be very meaningful. Also one can imagine that with increasing computational abilities, computers will be able to explore the infinite space of deductions at a much larger scale than human mathematicians and produce
complex, well-formed formulas that could be interesting. However, it is currently unclear if those formulas could be understood by humans and perhaps it would be necessary to develop ``translators'' in tandem. While a fertile area of research, this is not the focus of my current work and PhD. I believe that there is much to be gained by trying to learn from the predominant methods of mathematical discovery and trying to incorporate these into the AI models that are currently being developed.

\section{Interestingness}

\section{Implementation}
\label{sec:implementation}
Another major portion of work during my first year has been implementing the conjecture space. The goal is to have a pipeline that domain experts are able to use as an exploratory tool.
I describe the setup, current state and future ideas below.

\subsection{Basic Setup}
The basic setup is as follows (For notation and definitions please see \ref{sec:conj-space} and \ref{sec:ominimal-connexions}). My chosen programming language is Python along with standard libraries such as NumPy, SymPy etc. 
\begin{itemize}
    \item 
        \textbf{Input:} There are two allowed modes of input: (i)Providing both the domain, $\Omega$, and function box $\mathcal{F}$ (ii) Providing a finite set of real-valued function evaluations (Note: This is the discrete function graphs as in \ref{eq:graph}). Multiple implementations of $\Omega$ are supported: 
          \begin{itemize}
            \item[$\blacktriangleright$] As a discrete set of points (Can be useful if there are specific points/regions where a function is known to have interesting behaviour. For example, many number theoretic functions have intereseting behaviour at very large primes.)
            \item[$\blacktriangleright$] As an interval box, $\mathcal{I}^n = [min, max]\times_1...\times_n[min, max]$ with a choice of range and arbitrary precision (by varying the number of points).
          \end{itemize}
          In case (i), I utilize SymPy \cite{10.7717/peerj-cs.103} implementations of the functions where available or write a custom implementation that is compatible with SymPy. In case (ii), a symbol is assigned to the function evaluations and manipulated as a SymPy symbol. The function box then consists of all such symbols.
    \item 
        \textbf{Optimization:} As described in \ref{loss}, the optimization problem is finding tuples $\alpha = (\alpha_1,...,\alpha_{|\mathcal{F}|})$, such that the loss is zero. Let $\alpha_{init}\in\R^{|\mathcal{F}|}$ be an initial, randomly chosen tuple of coefficients.
        There are multiple options for loss functions, that satisfy the condition in \ref{loss}. I focus on a differentiable, signum-based loss function that is amenable to a number of different learning algorithms.
        \begin{definition}[Signum Loss]
            \label{def:signum-loss}
            I first define the `signum value' of an $(\alpha, \mathcal{F})$ pair as follows:
            \begin{equation*}
                \omega(\alpha, \mathcal{F}) = \frac{1}{|\Omega|}\sum_{x\in\Omega} \sgn\left(\sum_{i=1}^{|\mathcal{F}|}\alpha_i f_i(x)\right)
            \end{equation*}
            where $\sgn$ is the signum function. The signum loss is then defined as:
            \begin{equation*}
                \mathfrak{L}(\alpha,\mathcal{F}) = 1 - \omega(\alpha, \mathcal{F})^2
            \end{equation*}
            where $\sgn$ is the signum function. For simplicity of notation,
        \end{definition}
        \begin{algorithm}
        \caption{Pseudo-code for SGD with Signum Loss}\label{alg:SGD}
        \end{algorithm}   
    \item 
        \textbf{Output:} The output is a set of human-readable conjectures (in symbolic form). They have exactly zero loss over the chosen $\Omega$.
    
\end{itemize}
 

\subsection{Expanding parameterization with Symbolic Regression}
\subsection{Stuff with Eric, GP's?}
Setting up machine learning on the conjecture space where the goal is to implement heuristics of interestingness and understand how to choose our function boxes.
Topological entropy, betti number entropy definition etc. Topological entropy of a Banach space has been studied \cite{bobokTopologicalEntropyBanach2011}
talk about information content, entropy stuff here. Include what the issue with entropy directly is, some of the GP stuff maybe. Also connect to other ideas of interestingness I am exploring/have thought about atleast.

\section{Agent based math discovery}
Talk about how this is my plan in the future. First working on proof-of-concept and then hopefully new stuff.
Different agents working with different criteria of interestingness and different policies.
