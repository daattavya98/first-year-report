\chapter{A theoretical framework}
\textit{Conjecture space and interestingness}\\
\textit{Multi-agent systems for mathematical discovery (Nature of mathematical discovery discussed in introduction in detail)}

\section{The Conjecture Space}

The conjecture space was introduced in \cite{mishraConjGen2023} by Mishra et.al. This framework can be utilized as a tool to study conjectures that can be expressed as inequalities involving continuous functions. This is a starting point to explore the notion 
of a space of conjectures as a meta-mathematical tool that can be used for mathematical dicovery across sub-disciplines. One of the major goals of my thesis is to try to extend the formalism beyond inequalities involving continuous functions and cover wider classes of mathematical statements. 
I describe the conjecture space along with some useful results that help setup the arguments in this report below (\textit{In preparation: Challenger Mishra, Rahul Sarkar and Daattavya Aggarwal}).

\begin{definition}[Relation Space]
    \label{def:space-relations}
    Let $\Omega\in\R^n$ be a compact subset. Let $C(\Omega)$ denote the Banach space of continuous, real-valued functions on $\Omega$, equipped with the supremum norm, i.e.
    \begin{equation*}
        \norm{f}_{C(\Omega)} := \sup_{x\in\Omega} \left|f(x)\right|    
    \end{equation*}
    where a real-valued function is
    \begin{equation*}
        f:\Omega\rightarrow\R
    \end{equation*}
    We will call this Banach space as the \textit{Relation Space}, $\crlR$
\end{definition}

Following on from the definition of the Relation space ~\ref{def:space-relations}, we can define the \textit{Conjecture Space} as follows:
\begin{definition}[Conjecture Space]
    Let $f\in\crlR$. $f$ is an element of the \textit{Conjecture Space} if and only if $f(x) < 0 \;\forall x\in\Omega$ or $f(x) > 0 \; \forall x\in\Omega$.
    The set $\crlC = \crlC_{<}\cup\crlC_{>}$ is called the \textit{Conjecture Space} where $\crlC_{<} = \{f\in\crlR\;|\; f(x)<0\;\forall x\in\Omega\}$ and $\crlC_{>} = \{f\in\crlR\;|\;f(x)>0\;\forall x\in\Omega\}$.
    $\crlC_{<}$ and $\crlC_{>}$ are disjoint convex sets.
\end{definition}

There are some useful properties of $\crlC$ building upon \cite{mishraConjGen2023}. (Please see appendix \ref{app:conj-space} for further details).
\begin{itemize}
    \item $\crlC$ is an open subset of $\crlR$ and hence a Banach manifold. $\crlC_{<}$ and $\crlC_{>}$ are homeomorphic. (Note that $\crlC$ is not a Banach space. For example, it is not closed under addition)
    \item $\crlC$ forms an abelian group under (pointwise) multiplication. Moreover, $\crlC$ and $\crlC_{>}$ are topological groups with the subspace topology inherited from $\crlR$. 
\end{itemize}

\begin{lemma}[Action by $\text{Homeo}(\R^*)$]
    \label{lemma:homeo-action}
    $\crlC$ admits a group action $\mathsf{A}: \text{Homeo}(\R^*)\times\crlC\mapsto\crlC$ by elements of the group $\text{Homeo}(\R^*)$ defined by $\mathsf{A}(g,f) := g\circ f$\\
    Every $g\in\text{Homeo}(\R^*)$ defines a homeomorphism $\mu_g : \crlC\mapsto\crlC$ by $\mu_g(f) = \mathsf{A}(g,f)$. The restriction of $\mu_g$ on each of the connected components $\crlC_{<}$ and $\crlC_{>}$ is also a homeomorphism 
    with exactly one of the two cases holding: (i) $\mu_g(\crlC_{>}) = \crlC_{>},\; \mu_g(\crlC_{<}) = \crlC_{<}$ or (ii) $\mu_g(\crlC_{>}) = \crlC_{<},\; \mu_g(\crlC_{<}) = \crlC_{>}$.
\end{lemma}

Based on ~\ref{lemma:homeo-action}, we can define a notion of \textit{equivalent} conjectures.
\begin{definition}[Equivalent Conjectures]
    Two conjectures $f_1,f_2\in\crlC$ are said to be \textit{equivalent} if there exists a homeomorphism $h\in\text{Homeo}(\R^*)$ such that $\mathsf{A}(h, f_1) = f_2$. We write this as $f_1\sim f_2$.
\end{definition}    

\begin{prop}
    Equivalence of conjectures forms an equivalence relation under the group action $\mathsf{A}$.
\end{prop}
\begin{proof}
    I check the three required properties explicitly.
    \begin{itemize}
        \item \textbf{Reflexivity:} $f\sim f$ as $\mathsf{A}(\mathsf{I}, f) = \mathsf{I}\circ f = f$ where $\mathsf{I}$ is the identity homeomorphism.
        \item \textbf{Symmetry:} 
            \begin{align*}
                f_1\sim f_2 &\implies \exists h\in\text{Homeo}(\R^*) \text{ such that } \mathsf{A}(h, f_1) = f_2\\
                &h\in\text{Homeo}(\R^*)\implies \exists h^{-1}\in\text{Homeo}(\R^*) \text{ such that } \mathsf{A}(h^{-1}, f_2) = f_1\\
                &\implies f_2\sim f_1
            \end{align*}
        \item \textbf{Transitivity:}
            \begin{align*}
                f_1\sim f_2 &\implies \exists h_1\in\text{Homeo}(\R^*) \text{ such that } \mathsf{A}(h_1, f_1) = f_2\\
                f_2\sim f_3 &\implies \exists h_2\in\text{Homeo}(\R^*) \text{ such that } \mathsf{A}(h_2, f_2) = f_3\\
                &\implies \mathsf{A}(h_2, \mathsf{A}(h_1, f_1)) = f_3\\
                &\implies \mathsf{A}(h_2\circ h_1, f_1) = f_3\\
                &\implies f_1\sim f_3    
            \end{align*}
    \end{itemize}
\end{proof}

Now crucially, we want to ensure that our notion of \textit{equivalence} doesn't make the conjecture space trivial, that is, there is more than one equivalence class under this relation. This is equivalent to the existence of more than one orbit under the group action $\mathsf{A}$.
The next result ensures this.

\begin{theorem}[Orbit Characterization]
    Let $f_1, f_2\in\crlC$. $f_1,f_2$ belong to different orbits of $\mathsf{A}$, if there exist distinct points $x,y\in\Omega$ such that either (i)$f_1(x) = f_1(y)$ and $f_2(x)\neq f_2(y)$ or (ii)$f_1(x)\neq f_1(y)$ and $f_2(x) = f_2(y)$. The converse holds when $\Omega$ is path-connected.
\end{theorem}


% \subsection{Relevant functional analysis stuff}
% cite (Challenger paper) Might be able to extend the conjecture/relation space to a Banach lattice and not just a Banach space.
\section{Connections to model theory}
A major portion of my first year has been devoted to learn about model theory. I am trying to explore if there are connections to and tools from model theory that can be used to analyze the conjecture space in a systematic way and extend the formalism to a more general setting, i.e., beyond inequalities of continuous functions.
\subsection{Why model theory?}
In \cite{baldwin2020reasonable}, Baldwin contrasts Wigner's famous observations in \cite{wigner1990unreasonable} about the `unreasonable' effectiveness of mathematics in the natural sciences with the reasonable effectiveness of model theory across various areas of mathematics. Baldwin describes three key reasons for this effectiveness.
I believe these complement the conceptual framework of mathematical discovery that I am proposing for my thesis. These are as follows:
\begin{itemize}
    \item Representing an area of mathematics as the study of a collection of similar structures for a fixed vocabulary. Model theory has made rigorous the concept of \textit{interpretations}. This lets us compare these similar structures and know when they are equivalent, through notions like \textit{elementary equivalence}\footnote[1]{Please see \ref{def:elementary-equivalence}}.
    \item Restriction to \textit{definable}\footnote[2]{Please see \ref{def:definable-set}} subsets rather than all subsets of the structure.
    \item Results from \textit{Stability theory} which highlight combinatorial features that are present in very distinct areas of mathematics. 
\end{itemize} 

The crucial argument is captured by part of Baldwin's theses in \cite{Baldwin_2018} on contemporary model theory and the philosophy of mathematical practice.
\begin{itemize}
    \item The focus of contemporary model theory is utilizing formalization of \textit{specific} mathematical areas to investigate mathematical problems in general and issues in the philosophy of mathematics (methodology, axiomatization, compactness etc.)
    \item Modern model theory allows us to systematically compare \textit{local} formalizations for distinct mathematical areas allowing us to organize them and analyze mathematical practice.
\end{itemize}

I believe this focus on \textit{local} formalizations of specific areas is an essential feature of a math discovery system. This emulates the process of working mathematicians and avoids some of the shortcomings of global formalization. The decisive advantage of model theory is the ability to \textit{systematically compare} these formalizations and \textit{classify theories}\footnote[3]{A formal theory is a set of sentences in a formal language \cite{changModelTheory1990}}.
These are \textit{meta-mathematical tools} (Initially coined by the famous logician Tarski). They allow us to study these local theories as mathematical objects themselves. \\
Restriction to \textit{definable} subsets is natural and desirable in most of mathematics. Speaking loosely, `definable' objects in a structure are those which arise naturally, that is, when pathological cases are disallowed. As an example, focus on definable sets has led to understanding the method of quantifier elimination \cite{robinsonApplicationSymbolicLogic1952,TarskiDecisionMethod} which has wide ranging applications in algebra and field theory.
Stability theory has led to a  new direction that is epistemologically fruitful: the classification of complete, first-order theories into finitely many kinds. This allows for comparisons amongst local formalizations as described above.\\
A combination of these tools led to the discovery of \textit{o-minimality} in the 1980s \cite{pillayDefinableSetsOrdered1986, DENDRIES198497}. o-minimality has had successful applications in arithmetic geometry \cite{binyaminiWilkiesConjecturePfaffian2022,binyaminiBoundsRationalPoints2023}, analysis \cite{pilaOminimalityAndreOortConjecture2011}, hodge theory and recently even string theory \cite{douglasTamenessQuantumField2022,grimmComplexityTameQuantum2023,grimmFinitenessTheoremsCounting2023,grimmTamenessStringsDistance2022}!  
Some of the central questions I am interested in potentially link contemporary model theory to mathematical discovery:
\begin{itemize}
    \item Are there well understood meta-mathematical tools that can be incorporated in our math discovery system?
    \item 
\end{itemize}


% \input{Banach_space_model_theory_notes.tex}
\subsection{o-minimality approach}

cite Margaret Thomas paper \cite{thomasConvergenceResultsFunction2012}

\begin{theorem}[Monotinicity]
    Let $f:(a,b)\mapsto R$ be a definable function on the interval $(a,b).$ Then there are points $a_1 < ... < a_k$ in $(a,b)$ such that on each sub-interval $(a_j, a_{j+1})$ with $a_0 = a, a_{k+1} = b$, the function is either constant, or strictly monotone and continuous.
\end{theorem}

% \input{o-minimal_details.tex}

Consider $\R_{alg}$, the simplest o-minimal structure whose definable sets are exactly the semi-algebraic sets.

\begin{definition}[Semialgebraic]
    A semialgebraic set in $\R^n$ is by definition a finite union of sets of the form
    \begin{equation*}
        \{x\in\R^n : f(x) = 0, g_1(x)>0,...,g_k(x)>0\}
    \end{equation*}
    where $f$ and $g$'s are real polynomials in $n$ variables.
\end{definition}

We are interested in elements of the Relation space, $\crlR$, that is, $C^0$ real-valued functions, $f:\Omega\mapsto\R$, where $\Omega$ is a compact subset of $\R^n$.
\\\\
\textcolor{red}{I think the following example might be quite trivial but illustrates the concept}.
\\\\
Consider the simple case of $n=1$ with $\Omega$ being the set of integers from 1 to 1000, represented by $\mathbb{D}$.
As this is a finite union of singletons, it is definable in $\R_{alg}$. Now consider functions from number theory acting on singletons to give singletons as output. (Equipping $\mathbb{D}$ with the discrete topology ensures continuity). Suppose we consider the prime counting function $\pi(x)$ and Euler totient function $\varphi(x)$. Now, for integers $x > 90$, $\pi(x) < \varphi(x)$. (This is an inequality that was found by the conjecture machine and confirmed to be true from some number theory literature \cite{moser1951}).

Suppose we consider $A\subset\mathbb{D}$ where
\begin{equation*}
    A = \{30, 31,....,100\}
\end{equation*}
that is the set of singletons from 30 till 100. (This choice ensures that the inequality under consideration is true and thus the function we consider below is a ``conjecture" as per our definition).

By definition, $A\subset\mathbb{D}$ and hence $A\in\mathcal{S}^1 \implies $ definable.
\\\\
Now take the function $f: n\mapsto\varphi(n) - \pi(n)$ acting on the set A defined above. $\pi(A)\subset\mathbb{D}, \varphi(A)\subset\mathbb{D}$ and `-' is a closed operation on $\mathbb{D}$. Thus $\varphi(A) - \pi(A)$ must be in $\mathbb{D}$ and hence $f(A)\subset\mathbb{D}$.
\\\\
From the second axiom in the definition of o-minimal structures,

\begin{equation*}
    A \in \mathcal{S}_n\implies A \times\real\in\mathcal{S}_{n+1} \text{ and } \real \times A\in\mathcal{S}_{n+1}
\end{equation*}
\\
So if we consider the graph of $f$, $\Gamma(f)\subseteq\mathbb{D}^2$, we have that $\Gamma(f)$ is a set of points $(p,q)$ where $p\in P\subset\mathbb{D}$ and $q\in Q$ where $Q\in\mathbb{D}$. (As $f(A)\in\mathbb{D}$ from above.
\\\\
Now we know that $P\in\mathcal{S}_1, Q\in\mathcal{S}_1$. Thus by lemma 2.2 (i) [LVD]
\begin{equation*}
    A\in\mathcal{S}_m \text{ and } B\in\mathcal{S}_n \implies A\times B\in\mathcal{S}_{m+n}
\end{equation*}
$\Gamma(f)\in\mathcal{S}_2\implies$ \textbf{f is definable}.

This can be generalized for any tuple of singletons (in an analogous manner) and thus any function $f:\mathbb{D}^n\mapsto\mathbb{D}$ would be definable. For this to be potentially interesting, we want to extend the analysis to generic domains, meaning that we want to include finite unions of intervals and not just singletons.
\\\\
Generic Case:\\
$\Omega$ is a compact subset of $\real^n$. Thus by the Heine-Borel theorem, $\Omega$ must be closed and bounded. By definition, a bounded set is contained in an open ball, $B(a,r) = \{x\in\real^n:|x - a| < r\}$. \\$B(a, r)$ is definable in $\real_{alg}$ implying $\Omega$ is definable in our structure.

\begin{equation*}
    \exists r\;\forall x\in\Omega \quad (x - a) < r\; \vee \; (a - x) > r
\end{equation*}

Above is a finite union of intervals
\\\\
Now consider a  finite set of $C^0$ real-valued functions, $f:\Omega\mapsto\real$, $\mathcal{F} = \{f_1,...,f_k\}$. We also need a corresponding tuple of coefficients $\alpha = (\alpha_1,...,\alpha_k)$ and each $\alpha\in\real$.

These are the functions we want to base our conjectures on and the optimization problem is finding the possible tuples $\alpha$ such that our signum-based loss is exactly zero. This is equivalent to the following condition:
\begin{equation}
\label{loss}
    \alpha_1f_1(x)+\alpha_2f_2(x)+.....+\alpha_nf_n(x) > 0 \quad\forall x\in\Omega
\end{equation}

\begin{itemize}
    \item All $f_i$'s are definable functions: In this case, as a linear combination of definable functions will necessarily be definable, conjectures are definable.
    \item \textit{Approximation of functions}: Suppose one or more of the $f_i$'s are not definable. When calculating the signum-loss as in \ref{loss}, on any computing system, we are necessarily restricted to a \textit{finite} number of computations because $\Omega$ will always be finite. In this case, all of the $f_i$'s become discrete.
    \\\\ By almost a trivial argument, the I think the following should be true:

    Suppose the implementation of $\Omega$ on the computing system is represented by $\Omega^{comp}$. This is the set
    \begin{equation*}
        \Omega^{comp} = \{(a_i) : i\in I\} 
    \end{equation*}
    where $I$ is a finite index set (i.e. $I = \{1, 2, ..., k\}$ and each $a_i$ (term in the domain) is a real number up to arbitrary precision in floating point arithmetic.
    For any
    \begin{equation*}
        f:\Omega^{comp}\mapsto\real
    \end{equation*}
    $f(\Omega^{comp})$ is a \textit{finite} union (as $\Omega^{comp}$ is finite) of definable subsets of $\real\implies f(\Omega^{comp})$ is definable.
    \par Now, the domain and range of $f$ are definable and the graph of $f$ is a finite union of points,
    \begin{equation*}
        \Gamma(f) = \{(a_i, f(a_i)): a_i\in\Omega^{comp}\}
    \end{equation*}
    Hence the discrete version of $f_i$'s are definable.
\end{itemize}

The above argument seems quite trivial to me but I'm curious if it might still lead to any interesting developments in our setting.\\
Now after a very helpful discussion with Anuj, Ioannis and Challenger, I think the following observation might be interesting:
When dealing with these discrete functions (which we always have when implementing on a computing system), we can consider them to no longer be functions but simply constants (tuples) as the evaluation domain ($\Omega^{comp}$) is fixed. So we can append our language with constants, $c_1,...,c_n$, where each $c_i$ represents $f_i(\Omega^{comp})$. The object we are then trying to study is the definable set satisfying the following formula:

\begin{equation*}
    \exists\alpha_1\alpha_2....\alpha_n\quad\alpha_1c_1+\alpha_2c_2+...+\alpha_nc_n > 0
\end{equation*}

This definable set is the conjecture space. Some of the questions we want to explore: 
\begin{itemize}
    \item How can we study definable sets in this setting? Are their certain properties that are useful to analyze?
    \item Is there any connection between `meta-properties' of the conjecture space (interesting/trivial conjecture for example) and fundamental o-minimal geometric properties of this definable set (from finiteness, stratifications, decompositions etc.) \\ The goal is then to try to leverage these connections in a meaningful way
\end{itemize}



\textcolor{red}{From my understanding, these $a_i$ are the points that are contained in set. Hence the subdivisions are open and as we know that the set \ref{mn-set} is finite, $k$ is some finite integer. The question now is how to find these $a_i$. My guess is we need some condition on $f$ ``near" the $a_i$'s. One thing seems fairly easy to check, if the nature of $f$ changes at some point $x_0$, that is, on some interval before $x_0$, $f$ is let's say constant and on an interval immediately succeeding $x_0$, $f$ becomes strictly increasing or decreasing, $x_0$ must be one of the $a_i$. This is because if I consider any interval containing $x_0$, then lemma \ref{monotone-lemma} would fail. Aha! My hypothesis is that the $a_i$ are \textit{precisely} those points. As any other point can be subsumed into an interval surrounding it since that interval would satisfy lemma \ref{monotone-lemma}. The question is, what is a clever way to test the condition I am suggesting.}
\par
\textcolor{blue}{Is this problem similar to finding level sets?}

\textcolor{green}{\textbf{KEY HYPOTHESIS: DO WE HAVE AN O-MINIMAL STRUCTURE RELATED TO THE CONJECTURE SPACE, SUCH THAT,``GOOD/IMPORTANT" CONJECTURES 
ARE FUNDAMENTALLY RELATED TO THE O-MINIMAL/ ALGEBRAIC GEOMETRY OF THE SPACE IN TERMS OF STRATIFICATIONS, FINITENESS ETC.?}
}

Some preliminary ``evidence" (or why the idea came into my mind) is because of how the loss boundary for Robin's criteria for the Riemann Hypothesis might be resembling the kind of behaviour I would expect for the subdivisions of a definable function in an o-minimal structure in accordance with the monotonicity theorem.

\subsection{Extensions of above}

\subsection{Theorem spaces}
Whilst a ``space of conjectures'' is a potentially large leap from current literature, a related concept, ``space of theorems'', can be tackled via a variety of tools.
I define the ``space of theorems'', $\mathfrak{T}$ is the space of mathematical theorems. Note that this is a subset of the conjecture space as every element of $\mathfrak{T}$ trivially satisfies the membership criteria, i.e.,
there are no counter-examples to the theorem on any domain.
$\mathfrak{T}$ itself contains a furthermore rigorous subset, $\mathfrak{T}_F$, the ``space of formal theorems''. $\mathfrak{T}_F$ is the set of theorems that have been formalized in any formal system. Clearly $\mathfrak{T}_F\subset\mathfrak{T}$. A potential upside of working with $\mathfrak{T}_F$ is that their is a growing database of formalized theorems due to the widespread interest and ingenuity of the formalization community \cite{formalization_examples}.
Moreover a number of recent results have been published by training models by learning on datasets of formal theorems \cite{Deepmind_stuff}. A natural direction of inquiry is what is the relationship between these spaces? What is the connexion, if any, between the elements of these spaces?
\\\par
It is clear that $\mathfrak{T}_F\subset\mathfrak{T}\subset\mathfrak{Conj}$. The datasets based on $\mathfrak{T}_F$ can be leveraged for a variety of learning techniques. These models have achieved state-of-the-art accuracies on solving benchmark mathematics problems such as miniF2F, ProofNet, MATH and competition problem datasets such as IMO 2024 and the recently introduced PutnamBench. Improving AI models' ability to solve these tasks with formally verified proofs
is an extremely active and fruitful area of research. However, I argue that there is an obstruction to these models proving helpful for research and discovery in mathematics. I expand on this issue in an article I am currently working on (preprint to be available soon). 

\textcolor{red}{
An essential feature in applications of formalization and formal datasets is that an informal proof/solution already exists. Informal in this context refers to the notion of a formal proof as verified by a theorem proving system. Note that while the ability to formalize is at the heart of the field of mathematics and acceptance of proofs,
it is not a target that the working mathematician ever seeks to achieve in practice. The working mathematician's goal is to find proofs at the level of certainty that is accepted by the mathematical community and is fruitful to the progress of the discipline as a whole. Formal proofs as produced by systems such as Lean, Isabelle, Coq etc., although conceptually crucial, are often unintelligble to humans and well beyond the level of rigour that is needed by the community. Many formalization details are simply unnecessary and
intuitively already understood and internalized by mathematicians. Moreover, details of formalization can on occasion be extremely tedious and don't provide further insight into the problem.
\\
“My intellect never quite recovered from the strain of
writing [Principia Mathematica]. I have been ever since
definitely less capable of dealing with difficult
abstractions than I was before.” (Russell, Autobiography)
However, formalization is quickly becoming widely accepted by the mathematical community and is quickly becoming the expected standard for published research \cite{Tao, formalization_projects_to_check_shit}.
Increasing specialization making reviewing almost impossible, mistakes in math literature etc and the utility of previously models increasing.
}

The existence of solutions to problems in these datasets and ``informal'' proofs in literature are essential for these models to work as the existence of solutions and proofs \textbf{implies} that there is a configuration of axioms and deduction rules in your chosen formalization system that verifiably solves the problem/proves the theorem at hand.
The knowledge of the existence of such a solution/proof can by definition not exist for \textbf{new} research. Moreover, the set of possible formal statements is closed. This is because every element of $\mathfrak{T}_F$ is characterized by a specific \textit{deduction}\footnote[1]{A deduction from a set of sentences $\Gamma$ is a finite sequence \textbf{D} of formulas such that whenever a formula $A$ occurs in the sequence \textbf{D}, then either (i) $A\in\Gamma$, (ii) $A$ is an axiom (iii) A follows from the allowed inference rules applied to a sequence of formulas already appearing in \textbf{D}} in your chosen system of axioms and inference rules. 
If one works in classical logic, every well-formed formula in a given interpretation can only be either true or false. This implies that the concept of ``conjectures'' cannot exist in such a framework. By definition any well-formed formula is either true or false
and any statement that is not a well-formed formula simply cannot be parsed. Historically, mathematics has never developed in a ground up manner where every statement made is a logical consequence of previous statements. The ability to conjecture and pose questions (without knowing the answer) is crucial to mathematical research and creativity. As such, I would argue that it is unlikely to discover new, non-trivial mathematical results while being restricted to only making completely rigorous formal \textit{deductions}. Such a feat would be unprecedented.
However, including a ``pedantic'' formalizer as an agent in the process of discovery could be very meaningful. Also one can imagine that with increasing computational abilities, computers will be able to explore the infinite space of deductions at a much larger scale than human mathematicians and produce
complex, well-formed formulas that could be interesting. However, it is currently unclear if those formulas could be understood by humans and perhaps it would be necessary to develop ``translators'' in tandem. While a fertile area of research, this is not the focus of my current work and PhD. I believe that there is much to be gained by trying to learn from the predominant methods of mathematical discovery and trying to incorporate these into the AI models that are currently being developed.

\section{Interestingness}
talk about information content, entropy stuff here. Include what the issue with entropy directly is, some of the GP stuff maybe. Also connect to other ideas of interestingness I am exploring/have thought about atleast.

\section{Implementation}
\subsection{Basic Setup + GP's? Symbolic pipeline?}
Describe first my codebase and results. Then talk about stuff with Eric(where it's at, current work and hopefully package soon) and finally symbolic pipeline things.
\subsection{Stuff with Eric}
Setting up machine learning on the conjecture space where the goal is to implement heuristics of interestingness and understand how to choose our function boxes.
Topological entropy, betti number entropy definition etc. Topological entropy of a Banach space has been studied \cite{bobokTopologicalEntropyBanach2011}

\section{Agent based math discovery}
Talk about how this is my plan in the future. First working on proof-of-concept and then hopefully new stuff.
Different agents working with different criteria of interestingness and different policies.
